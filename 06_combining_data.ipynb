{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Combining Data for use in Tableau**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to create an interactive dashboard for tableau, but to do that, we'll need to combine our data and add some new columns. Some features we'll need to add to the data include:\n",
    "* `date_announcement_normalized` - an ordinal column for the date that can be used to align states based on their closing/reopening announcement date. Thinking of using a +/- shutdown date to create this column.\n",
    "* `is_reopen` - a boolean column that will say whether the row is from the state's opening or closing phase. Will do this by applying a True/False to all reopening or closing dataframes before doing a union."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_reopen = pd.read_csv('./data/sentiment_data/MI_reopen_sentiment.csv')\n",
    "# oh_reopen = pd.read_csv('./data/sentiment_data/OH_reopen_sentiment.csv')\n",
    "mi_shutdown = pd.read_csv('./data/sentiment_data/MI_shutdown_sentiment.csv')\n",
    "# oh_shutdown = pd.read_csv('./data/sentiment_data/OH_shutdown_sentiment.csv')\n",
    "# tx_reopen = pd.read_csv('./data/sentiment_data/TX_reopen_sentiment.csv')\n",
    "# ga_reopen = pd.read_csv('./data/sentiment_data/GA_reopen_sentiment.csv')\n",
    "# il_reopen = pd.read_csv('./data/sentiment_data/IL_reopen_sentiment.csv')\n",
    "tx_shutdown = pd.read_csv('./data/sentiment_data/TX_shutdown_sentiment.csv')\n",
    "# ga_shutdown = pd.read_csv('./data/sentiment_data/GA_shutdown_sentiment.csv')\n",
    "# il_shutdown = pd.read_csv('./data/sentiment_data/IL_shutdown_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_reopen.rename(columns={'formatted_date' : 'date'}).to_csv('./data/sentiment_data/MI_reopen_sentiment.csv', index=False)\n",
    "# oh_reopen.rename(columns={'formatted_date' : 'date'}).to_csv('./data/sentiment_data/OH_reopen_sentiment.csv', index=False)\n",
    "mi_shutdown.rename(columns={'formatted_date' : 'date'}).to_csv('./data/sentiment_data/MI_shutdown_sentiment.csv', index=False)\n",
    "# oh_shutdown.rename(columns={'formatted_date' : 'date'}).to_csv('./data/sentiment_data/OH_shutdown_sentiment.csv', index=False)\n",
    "# tx_reopen.rename(columns={'formatted_date' : 'date'}).to_csv('./data/sentiment_data/TX_reopen_sentiment.csv', index=False)\n",
    "# il_reopen.rename(columns={'formatted_date' : 'date'}).to_csv('./data/sentiment_data/IL_reopen_sentiment.csv', index=False)\n",
    "# ga_reopen.rename(columns={'formatted_date' : 'date'}).to_csv('./data/sentiment_data/GA_reopen_sentiment.csv', index=False)\n",
    "tx_shutdown.rename(columns={'formatted_date' : 'date'}).to_csv('./data/sentiment_data/TX_shutdown_sentiment.csv', index=False)\n",
    "# il_shutdown.rename(columns={'formatted_date' : 'date'}).to_csv('./data/sentiment_data/IL_shutdown_sentiment.csv', index=False)\n",
    "# ga_shutdown.rename(columns={'formatted_date' : 'date'}).to_csv('./data/sentiment_data/GA_shutdown_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_to_remove = ['eagle river ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'./data/sentiment_data//MI_shutdown_sentiment.csv')\n",
    "df.drop_duplicates(subset=['username', 'date'], keep='first', inplace=True) # need to remove any potential duplicates from overlapping city areas\n",
    "\n",
    "# Clean up final df\n",
    "df = df[(df['username'] != 'username') & # Removes headers leftover from scraping\n",
    "       (~df['city'].isin(cities_to_remove))] # Removes the cities that we need to remove\n",
    "df.dropna(subset=['text', 'date'], inplace=True) # There were some nulls in the text and date column that are likely the result of deleted/private tweets\n",
    "df.to_csv(f'./data/sentiment_data/MI_shutdown_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_date_col(rel_path='./data/sentiment_data'):\n",
    "    filenames = [filename for filename in os.listdir(rel_path) if filename.startswith('MI')]\n",
    "    for filename in filenames:\n",
    "        data = pd.read_csv(f'./data/sentiment_data/{filename}')\n",
    "        data.rename(columns={'formatted_date' : 'date'}).to_csv(f'./data/sentiment_data/{filename}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_date_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_and_add_cols(rel_path='./data/sentiment_data'):\n",
    "    '''\n",
    "    This function combines and adds columns to the csvs that\n",
    "    contain sentiment analysis data. Specifically, this function\n",
    "    adds the following features:\n",
    "    \n",
    "    date_ord: creates an ordinal value from the date column\n",
    "    \n",
    "    -----------------------\n",
    "    Parameters:\n",
    "    \n",
    "    rel_path : str, the path where all of your csvs are stored\n",
    "    '''    \n",
    "    # Getting all of a state's filenames\n",
    "    filenames = [filename for filename in os.listdir(rel_path) if filename.endswith('.csv')]\n",
    "    \n",
    "    # Create new df so the final df doesn't keep appending if you need to run again\n",
    "    # First, we'll need to get the headers - thanks Tyler on SO for this\n",
    "    # https://stackoverflow.com/questions/24962908/how-can-i-read-only-the-header-column-of-a-csv-file-using-python\n",
    "#     with open(f'{rel_path}/{filenames[0]}', 'r') as f:\n",
    "#         reader = csv.DictReader(f)\n",
    "#         fieldnames = reader.fieldnames\n",
    "\n",
    "#     # Write a clean df\n",
    "#     pd.DataFrame(columns=fieldnames + ['']).to_csv(f'{rel_path}/combined/all_states_and_dates_sentiment.csv', index=False) # THIS DIDNT\" NEED TO BE A VARIABLE ++++ REMOVE WHEN DONE\n",
    "    \n",
    "    # We'll need this dict for later, the values are organized as [shutdown_date_announced, reopening_date]\n",
    "    timeline_dict = {\n",
    "        'FL': ['2020-04-01', '2020-04-29'],\n",
    "        'TX': ['2020-03-31', '2020-05-18'],\n",
    "        'NJ': ['2020-03-16', '2020-06-09'],\n",
    "        'NY': ['2020-03-22', '2020-06-13'],\n",
    "        'IL': ['2020-03-20', '2020-05-29'],\n",
    "        'GA': ['2020-04-02', '2020-06-01'],\n",
    "        'OH': ['2020-03-22', '2020-05-12'],\n",
    "        'MI': ['2020-03-23', '2020-06-01']\n",
    "    }\n",
    "        \n",
    "    # Main combination loop\n",
    "    for filename in filenames:\n",
    "        df = pd.read_csv(f'{rel_path}/{filename}')\n",
    "        \n",
    "        #-----------IS REOPEN-------------\n",
    "        '''\n",
    "        We want to add a column that tells us if the row is \n",
    "        from reopening or shutdown data, we'll do this by\n",
    "        referencing the filenames since that data is included there\n",
    "        '''\n",
    "        \n",
    "        if filename.split('_')[1] == 'shutdown':\n",
    "            df['is_reopen'] = False\n",
    "            is_reopen = False # Setting this for later use\n",
    "        else:\n",
    "            df['is_reopen'] = True\n",
    "            is_reopen = True # Setting this for later use\n",
    "            \n",
    "        \n",
    "        #--------ORDINAL NORMALIZATION-----------\n",
    "        '''\n",
    "        The following code will set the shutdown/reopening \n",
    "        date as 0, so we can align states on a graph based on this date.\n",
    "        '''\n",
    "        \n",
    "        # converting date to datetime\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "        # setting date as index\n",
    "        df.set_index('date', inplace=True, drop=False)\n",
    "        \n",
    "        # State name pulled from filename\n",
    "        state_name = filename.split('_')[0]\n",
    "        \n",
    "        announce_date = timeline_dict[state_name][is_reopen]\n",
    "        \n",
    "        # Setting the announcement day and hour (since not every dataset has noon, \n",
    "        # we're using the last tweet from the announcement day as our midpoint\n",
    "        announcement_day_hour = df[f'{announce_date}']['date'][len(df[announce_date])//2] # this will pick the middle entry from the announcement day\n",
    "\n",
    "        # Take the time delta in seconds divided by 60 ** 2 to get nubmer of hours\n",
    "        df['date_announcement_normalized'] = df.apply(lambda x: (x['date'] - announcement_day_hour).total_seconds() // 60 ** 2, axis=1)\n",
    "\n",
    "            \n",
    "        #----------WRITE TO FINAL DF--------\n",
    "        \n",
    "        if filename == filenames[0]:\n",
    "            # Write to final df\n",
    "            df.to_csv(f'{rel_path}/combined/all_states_and_dates_sentiment.csv', index=False)\n",
    "        else:\n",
    "            # Append to final df\n",
    "            df.to_csv(f'{rel_path}/combined/all_states_and_dates_sentiment.csv', index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_and_add_cols('./data/sentiment_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
